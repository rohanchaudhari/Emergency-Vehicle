{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "#from resnets_utils import *\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = r'C:\\Users\\Aishwarya\\Documents\\GitHub\\Emergency-Vehicle-Recognition\\Python Notebook\\Data\\train\\train_images'\n",
    "\n",
    "image = Image.open(path1 + r'\\706.jpg')\n",
    "data = asarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1646, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((1646,224,224,3))\n",
    "\n",
    "a[0,:,:,:] = data\n",
    "\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((1646,224,224,3))\n",
    "\n",
    "path1 = r'C:\\Users\\Aishwarya\\Documents\\GitHub\\Emergency-Vehicle-Recognition\\Python Notebook\\Data\\train\\train_images'\n",
    "\n",
    "dir = os.listdir(path1) # original directory with all images  \n",
    "counter = 0\n",
    "count2 = 0\n",
    "all_image_names = []\n",
    "for i in dir:\n",
    "    all_image_names.append(int(i.split('.')[0]))\n",
    "\n",
    "all_image_names = sorted(all_image_names)\n",
    "    \n",
    "\n",
    "for i in all_image_names: \n",
    "    \n",
    "    \n",
    "    image = Image.open(path1 + r'\\\\'+ str(i) + '.jpg')\n",
    "    data = asarray(image)\n",
    "    #print(i)\n",
    "    a[counter,:,:,:] = data\n",
    "    \n",
    "    data = 0\n",
    "    counter += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[115. 134. 141.]\n",
      "   [116. 135. 142.]\n",
      "   [116. 135. 142.]\n",
      "   ...\n",
      "   [ 70.  81.  87.]\n",
      "   [ 74.  85.  91.]\n",
      "   [ 82.  93.  99.]]\n",
      "\n",
      "  [[115. 134. 141.]\n",
      "   [116. 135. 142.]\n",
      "   [116. 135. 142.]\n",
      "   ...\n",
      "   [ 82.  93.  99.]\n",
      "   [ 82.  93.  99.]\n",
      "   [ 83.  94. 100.]]\n",
      "\n",
      "  [[115. 134. 141.]\n",
      "   [116. 135. 142.]\n",
      "   [116. 135. 142.]\n",
      "   ...\n",
      "   [ 77.  88.  94.]\n",
      "   [ 75.  86.  92.]\n",
      "   [ 76.  87.  93.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 39.  39.  37.]\n",
      "   [ 36.  36.  34.]\n",
      "   [ 35.  35.  33.]\n",
      "   ...\n",
      "   [ 42.  41.  39.]\n",
      "   [ 45.  44.  42.]\n",
      "   [ 43.  42.  40.]]\n",
      "\n",
      "  [[ 38.  38.  36.]\n",
      "   [ 37.  37.  35.]\n",
      "   [ 36.  36.  34.]\n",
      "   ...\n",
      "   [ 45.  44.  42.]\n",
      "   [ 43.  42.  40.]\n",
      "   [ 34.  33.  31.]]\n",
      "\n",
      "  [[ 33.  33.  31.]\n",
      "   [ 33.  33.  31.]\n",
      "   [ 32.  32.  30.]\n",
      "   ...\n",
      "   [ 43.  42.  40.]\n",
      "   [ 34.  33.  31.]\n",
      "   [ 20.  19.  17.]]]\n",
      "\n",
      "\n",
      " [[[ 30.  29.  24.]\n",
      "   [ 21.  20.  15.]\n",
      "   [ 19.  18.  13.]\n",
      "   ...\n",
      "   [ 17.  13.  10.]\n",
      "   [ 16.  12.   9.]\n",
      "   [ 15.  11.   8.]]\n",
      "\n",
      "  [[ 26.  25.  20.]\n",
      "   [ 19.  18.  13.]\n",
      "   [ 17.  16.  11.]\n",
      "   ...\n",
      "   [ 16.  12.   9.]\n",
      "   [ 14.  10.   7.]\n",
      "   [ 11.   7.   4.]]\n",
      "\n",
      "  [[ 23.  23.  15.]\n",
      "   [ 17.  16.  11.]\n",
      "   [ 16.  15.  10.]\n",
      "   ...\n",
      "   [ 13.   9.   6.]\n",
      "   [ 13.   9.   6.]\n",
      "   [ 13.   9.   6.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 70.  75.  78.]\n",
      "   [ 69.  74.  77.]\n",
      "   [ 70.  75.  78.]\n",
      "   ...\n",
      "   [ 39.  43.  46.]\n",
      "   [ 37.  41.  44.]\n",
      "   [ 34.  38.  41.]]\n",
      "\n",
      "  [[ 68.  73.  76.]\n",
      "   [ 68.  73.  76.]\n",
      "   [ 69.  74.  77.]\n",
      "   ...\n",
      "   [ 37.  41.  44.]\n",
      "   [ 37.  41.  44.]\n",
      "   [ 37.  41.  44.]]\n",
      "\n",
      "  [[ 73.  78.  81.]\n",
      "   [ 73.  78.  81.]\n",
      "   [ 75.  80.  83.]\n",
      "   ...\n",
      "   [ 30.  34.  37.]\n",
      "   [ 33.  37.  40.]\n",
      "   [ 37.  41.  44.]]]\n",
      "\n",
      "\n",
      " [[[ 86. 123. 152.]\n",
      "   [ 91. 130. 161.]\n",
      "   [ 76. 115. 146.]\n",
      "   ...\n",
      "   [180. 201. 222.]\n",
      "   [181. 201. 225.]\n",
      "   [181. 201. 225.]]\n",
      "\n",
      "  [[ 89. 126. 155.]\n",
      "   [ 96. 133. 162.]\n",
      "   [ 82. 119. 148.]\n",
      "   ...\n",
      "   [181. 202. 223.]\n",
      "   [181. 201. 225.]\n",
      "   [181. 201. 225.]]\n",
      "\n",
      "  [[ 87. 124. 153.]\n",
      "   [ 94. 131. 160.]\n",
      "   [ 80. 117. 146.]\n",
      "   ...\n",
      "   [181. 201. 225.]\n",
      "   [182. 202. 226.]\n",
      "   [181. 203. 226.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[113. 103.  93.]\n",
      "   [113. 103.  93.]\n",
      "   [111. 101.  89.]\n",
      "   ...\n",
      "   [133. 127. 129.]\n",
      "   [138. 132. 132.]\n",
      "   [126. 120. 120.]]\n",
      "\n",
      "  [[112. 102.  92.]\n",
      "   [112. 102.  92.]\n",
      "   [111. 101.  89.]\n",
      "   ...\n",
      "   [130. 124. 126.]\n",
      "   [135. 129. 129.]\n",
      "   [123. 117. 117.]]\n",
      "\n",
      "  [[107.  97.  87.]\n",
      "   [108.  98.  88.]\n",
      "   [108.  98.  86.]\n",
      "   ...\n",
      "   [138. 132. 134.]\n",
      "   [150. 144. 144.]\n",
      "   [142. 136. 136.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[195. 221. 248.]\n",
      "   [214. 237. 255.]\n",
      "   [202. 224. 255.]\n",
      "   ...\n",
      "   [204. 226. 250.]\n",
      "   [204. 226. 250.]\n",
      "   [204. 226. 250.]]\n",
      "\n",
      "  [[204. 229. 251.]\n",
      "   [207. 230. 255.]\n",
      "   [201. 222. 255.]\n",
      "   ...\n",
      "   [204. 226. 250.]\n",
      "   [204. 226. 250.]\n",
      "   [204. 226. 250.]]\n",
      "\n",
      "  [[219. 241. 254.]\n",
      "   [207. 227. 251.]\n",
      "   [206. 226. 255.]\n",
      "   ...\n",
      "   [204. 226. 250.]\n",
      "   [204. 226. 250.]\n",
      "   [204. 226. 250.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[218. 215. 208.]\n",
      "   [219. 216. 209.]\n",
      "   [223. 220. 213.]\n",
      "   ...\n",
      "   [218. 214. 205.]\n",
      "   [208. 204. 195.]\n",
      "   [234. 230. 221.]]\n",
      "\n",
      "  [[212. 209. 202.]\n",
      "   [220. 217. 210.]\n",
      "   [230. 227. 220.]\n",
      "   ...\n",
      "   [205. 201. 190.]\n",
      "   [215. 211. 200.]\n",
      "   [221. 217. 206.]]\n",
      "\n",
      "  [[217. 214. 207.]\n",
      "   [218. 215. 208.]\n",
      "   [218. 215. 208.]\n",
      "   ...\n",
      "   [204. 200. 189.]\n",
      "   [231. 227. 216.]\n",
      "   [196. 192. 181.]]]\n",
      "\n",
      "\n",
      " [[[253. 248. 252.]\n",
      "   [246. 241. 245.]\n",
      "   [160. 154. 158.]\n",
      "   ...\n",
      "   [101.  74.  65.]\n",
      "   [ 97.  70.  61.]\n",
      "   [ 96.  69.  60.]]\n",
      "\n",
      "  [[255. 252. 255.]\n",
      "   [255. 253. 255.]\n",
      "   [206. 200. 204.]\n",
      "   ...\n",
      "   [104.  77.  68.]\n",
      "   [101.  74.  65.]\n",
      "   [100.  73.  64.]]\n",
      "\n",
      "  [[255. 250. 254.]\n",
      "   [255. 252. 255.]\n",
      "   [241. 235. 239.]\n",
      "   ...\n",
      "   [103.  76.  65.]\n",
      "   [101.  74.  65.]\n",
      "   [100.  73.  64.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 32.  31.  29.]\n",
      "   [ 34.  33.  31.]\n",
      "   [ 36.  35.  33.]\n",
      "   ...\n",
      "   [144. 122.  98.]\n",
      "   [141. 121.  96.]\n",
      "   [140. 120.  95.]]\n",
      "\n",
      "  [[ 34.  33.  31.]\n",
      "   [ 35.  34.  32.]\n",
      "   [ 37.  36.  34.]\n",
      "   ...\n",
      "   [141. 121.  96.]\n",
      "   [140. 120.  95.]\n",
      "   [138. 118.  93.]]\n",
      "\n",
      "  [[ 36.  35.  33.]\n",
      "   [ 37.  36.  34.]\n",
      "   [ 38.  37.  35.]\n",
      "   ...\n",
      "   [140. 120.  95.]\n",
      "   [138. 118.  93.]\n",
      "   [137. 117.  92.]]]\n",
      "\n",
      "\n",
      " [[[104. 119.  28.]\n",
      "   [138. 152.  64.]\n",
      "   [ 85.  99.  14.]\n",
      "   ...\n",
      "   [212. 185. 156.]\n",
      "   [199. 162. 117.]\n",
      "   [228. 183. 128.]]\n",
      "\n",
      "  [[111. 126.  35.]\n",
      "   [163. 177.  89.]\n",
      "   [ 65.  79.   0.]\n",
      "   ...\n",
      "   [221. 196. 166.]\n",
      "   [196. 159. 114.]\n",
      "   [232. 189. 134.]]\n",
      "\n",
      "  [[ 87. 101.  13.]\n",
      "   [ 97. 111.  24.]\n",
      "   [ 96. 109.  27.]\n",
      "   ...\n",
      "   [231. 208. 177.]\n",
      "   [186. 152. 106.]\n",
      "   [230. 187. 132.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[143. 143. 135.]\n",
      "   [160. 160. 152.]\n",
      "   [164. 164. 156.]\n",
      "   ...\n",
      "   [103. 100.  49.]\n",
      "   [ 97.  93.  45.]\n",
      "   [121. 117.  70.]]\n",
      "\n",
      "  [[147. 147. 139.]\n",
      "   [149. 149. 141.]\n",
      "   [143. 143. 135.]\n",
      "   ...\n",
      "   [105. 103.  44.]\n",
      "   [ 77.  74.  19.]\n",
      "   [ 93.  90.  37.]]\n",
      "\n",
      "  [[156. 156. 148.]\n",
      "   [144. 144. 136.]\n",
      "   [141. 141. 133.]\n",
      "   ...\n",
      "   [134. 133.  69.]\n",
      "   [152. 150.  91.]\n",
      "   [145. 140.  84.]]]]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1646, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Indices :  1318\n",
      "Validation Set Indices :  328\n"
     ]
    }
   ],
   "source": [
    "random.seed(5)\n",
    "all_indices = [i for i in range(1646)]\n",
    "train_indices = random.sample(range(1646), 1318)\n",
    "print(\"Training Set Indices : \",len(train_indices))\n",
    "valid_indices = [i for i in all_indices if i not in train_indices]\n",
    "print(\"Validation Set Indices : \",len(valid_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1318\n",
      "[[[[ 11.  12.   7.]\n",
      "   [ 21.  22.  17.]\n",
      "   [ 17.  18.  13.]\n",
      "   ...\n",
      "   [ 11.  11.  11.]\n",
      "   [ 11.  11.  11.]\n",
      "   [ 19.  19.  19.]]\n",
      "\n",
      "  [[  7.   8.   3.]\n",
      "   [ 19.  20.  15.]\n",
      "   [ 12.  13.   8.]\n",
      "   ...\n",
      "   [ 16.  16.  16.]\n",
      "   [ 15.  15.  15.]\n",
      "   [ 22.  22.  22.]]\n",
      "\n",
      "  [[ 10.  11.   6.]\n",
      "   [ 14.  15.  10.]\n",
      "   [  6.   7.   2.]\n",
      "   ...\n",
      "   [ 13.  13.  13.]\n",
      "   [ 12.  12.  12.]\n",
      "   [ 17.  17.  17.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 65.  64.  62.]\n",
      "   [ 66.  65.  63.]\n",
      "   [ 62.  61.  59.]\n",
      "   ...\n",
      "   [ 94.  84.  74.]\n",
      "   [ 95.  85.  75.]\n",
      "   [ 96.  86.  76.]]\n",
      "\n",
      "  [[ 61.  60.  58.]\n",
      "   [ 69.  68.  66.]\n",
      "   [ 63.  62.  60.]\n",
      "   ...\n",
      "   [ 93.  83.  73.]\n",
      "   [ 95.  85.  75.]\n",
      "   [ 96.  86.  76.]]\n",
      "\n",
      "  [[ 59.  58.  56.]\n",
      "   [ 72.  71.  69.]\n",
      "   [ 64.  63.  61.]\n",
      "   ...\n",
      "   [ 92.  82.  72.]\n",
      "   [ 94.  84.  74.]\n",
      "   [ 95.  85.  75.]]]\n",
      "\n",
      "\n",
      " [[[223. 241. 255.]\n",
      "   [138. 156. 170.]\n",
      "   [140. 156. 171.]\n",
      "   ...\n",
      "   [255. 255. 255.]\n",
      "   [255. 255. 255.]\n",
      "   [255. 255. 255.]]\n",
      "\n",
      "  [[203. 220. 236.]\n",
      "   [154. 170. 185.]\n",
      "   [159. 175. 190.]\n",
      "   ...\n",
      "   [255. 255. 255.]\n",
      "   [255. 255. 255.]\n",
      "   [255. 255. 255.]]\n",
      "\n",
      "  [[164. 180. 196.]\n",
      "   [161. 177. 192.]\n",
      "   [145. 161. 176.]\n",
      "   ...\n",
      "   [255. 255. 255.]\n",
      "   [255. 255. 255.]\n",
      "   [255. 255. 255.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[138. 137. 135.]\n",
      "   [141. 140. 138.]\n",
      "   [137. 136. 134.]\n",
      "   ...\n",
      "   [102. 101.  97.]\n",
      "   [106. 102.  99.]\n",
      "   [106. 102.  99.]]\n",
      "\n",
      "  [[146. 145. 143.]\n",
      "   [149. 148. 146.]\n",
      "   [145. 144. 142.]\n",
      "   ...\n",
      "   [106. 105. 101.]\n",
      "   [108. 104. 101.]\n",
      "   [108. 104. 101.]]\n",
      "\n",
      "  [[152. 151. 149.]\n",
      "   [156. 155. 153.]\n",
      "   [152. 151. 149.]\n",
      "   ...\n",
      "   [110. 109. 105.]\n",
      "   [110. 106. 103.]\n",
      "   [108. 104. 101.]]]\n",
      "\n",
      "\n",
      " [[[163. 198. 230.]\n",
      "   [163. 198. 230.]\n",
      "   [163. 198. 230.]\n",
      "   ...\n",
      "   [166. 202. 226.]\n",
      "   [166. 202. 226.]\n",
      "   [166. 202. 226.]]\n",
      "\n",
      "  [[163. 198. 230.]\n",
      "   [163. 198. 230.]\n",
      "   [163. 198. 230.]\n",
      "   ...\n",
      "   [166. 202. 226.]\n",
      "   [166. 202. 226.]\n",
      "   [166. 202. 226.]]\n",
      "\n",
      "  [[163. 198. 230.]\n",
      "   [163. 198. 230.]\n",
      "   [163. 198. 230.]\n",
      "   ...\n",
      "   [166. 202. 226.]\n",
      "   [166. 202. 226.]\n",
      "   [166. 202. 226.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[172. 172. 164.]\n",
      "   [131. 131. 123.]\n",
      "   [163. 163. 155.]\n",
      "   ...\n",
      "   [190. 190. 182.]\n",
      "   [152. 152. 144.]\n",
      "   [173. 173. 165.]]\n",
      "\n",
      "  [[142. 142. 134.]\n",
      "   [136. 136. 128.]\n",
      "   [125. 125. 117.]\n",
      "   ...\n",
      "   [124. 124. 116.]\n",
      "   [131. 131. 123.]\n",
      "   [145. 145. 137.]]\n",
      "\n",
      "  [[153. 153. 145.]\n",
      "   [150. 150. 142.]\n",
      "   [134. 134. 126.]\n",
      "   ...\n",
      "   [120. 120. 112.]\n",
      "   [124. 124. 116.]\n",
      "   [190. 190. 182.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 18.  29.   0.]\n",
      "   [130. 139.  96.]\n",
      "   [201. 206. 183.]\n",
      "   ...\n",
      "   [230. 225. 219.]\n",
      "   [208. 203. 197.]\n",
      "   [221. 216. 210.]]\n",
      "\n",
      "  [[ 86.  97.  37.]\n",
      "   [133. 142.  99.]\n",
      "   [204. 209. 187.]\n",
      "   ...\n",
      "   [216. 211. 205.]\n",
      "   [227. 222. 216.]\n",
      "   [228. 223. 217.]]\n",
      "\n",
      "  [[134. 145.  87.]\n",
      "   [114. 122.  81.]\n",
      "   [133. 138. 118.]\n",
      "   ...\n",
      "   [199. 194. 188.]\n",
      "   [236. 231. 225.]\n",
      "   [224. 219. 213.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[100.  99.  69.]\n",
      "   [ 74.  74.  46.]\n",
      "   [ 41.  45.  22.]\n",
      "   ...\n",
      "   [ 90.  95.  65.]\n",
      "   [115. 120.  88.]\n",
      "   [ 88.  93.  61.]]\n",
      "\n",
      "  [[138. 139. 108.]\n",
      "   [131. 134. 107.]\n",
      "   [125. 130. 107.]\n",
      "   ...\n",
      "   [181. 185. 150.]\n",
      "   [ 75.  79.  44.]\n",
      "   [112. 116.  79.]]\n",
      "\n",
      "  [[137. 140. 109.]\n",
      "   [ 40.  44.  17.]\n",
      "   [ 94. 102.  79.]\n",
      "   ...\n",
      "   [108. 112.  75.]\n",
      "   [ 50.  55.  15.]\n",
      "   [ 90.  95.  55.]]]\n",
      "\n",
      "\n",
      " [[[116. 110.  84.]\n",
      "   [115. 108.  80.]\n",
      "   [125. 116.  85.]\n",
      "   ...\n",
      "   [245. 255. 255.]\n",
      "   [ 44.  51.  57.]\n",
      "   [ 21.  26.  32.]]\n",
      "\n",
      "  [[ 24.  20.   0.]\n",
      "   [ 59.  53.  27.]\n",
      "   [ 67.  60.  31.]\n",
      "   ...\n",
      "   [234. 248. 249.]\n",
      "   [ 39.  47.  50.]\n",
      "   [ 35.  40.  44.]]\n",
      "\n",
      "  [[ 29.  28.   8.]\n",
      "   [ 68.  66.  45.]\n",
      "   [ 73.  69.  44.]\n",
      "   ...\n",
      "   [205. 217. 217.]\n",
      "   [ 63.  71.  73.]\n",
      "   [ 10.  14.  17.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 10.  10.   8.]\n",
      "   [ 11.  11.   9.]\n",
      "   [ 12.  12.  10.]\n",
      "   ...\n",
      "   [ 13.  15.  14.]\n",
      "   [ 16.  18.  17.]\n",
      "   [ 19.  21.  20.]]\n",
      "\n",
      "  [[ 10.  10.   8.]\n",
      "   [ 11.  11.   9.]\n",
      "   [ 12.  12.  10.]\n",
      "   ...\n",
      "   [ 14.  16.  15.]\n",
      "   [ 18.  20.  19.]\n",
      "   [ 21.  23.  22.]]\n",
      "\n",
      "  [[ 10.  10.   8.]\n",
      "   [ 11.  11.   9.]\n",
      "   [ 12.  12.  10.]\n",
      "   ...\n",
      "   [ 16.  18.  17.]\n",
      "   [ 19.  21.  20.]\n",
      "   [ 22.  24.  23.]]]\n",
      "\n",
      "\n",
      " [[[106. 107. 102.]\n",
      "   [ 69.  70.  65.]\n",
      "   [ 63.  64.  59.]\n",
      "   ...\n",
      "   [ 49.  24.  28.]\n",
      "   [ 48.  21.  14.]\n",
      "   [ 38.  19.   4.]]\n",
      "\n",
      "  [[110. 110. 110.]\n",
      "   [154. 154. 154.]\n",
      "   [138. 138. 138.]\n",
      "   ...\n",
      "   [108.  92.  93.]\n",
      "   [154. 135. 128.]\n",
      "   [163. 147. 132.]]\n",
      "\n",
      "  [[137. 136. 141.]\n",
      "   [175. 174. 179.]\n",
      "   [110. 109. 114.]\n",
      "   ...\n",
      "   [101. 100.  98.]\n",
      "   [ 50.  41.  32.]\n",
      "   [ 50.  42.  29.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[105. 105. 107.]\n",
      "   [106. 106. 108.]\n",
      "   [109. 109. 111.]\n",
      "   ...\n",
      "   [122. 121. 119.]\n",
      "   [129. 128. 126.]\n",
      "   [135. 134. 132.]]\n",
      "\n",
      "  [[103. 103. 105.]\n",
      "   [104. 104. 106.]\n",
      "   [105. 105. 107.]\n",
      "   ...\n",
      "   [125. 124. 122.]\n",
      "   [129. 128. 126.]\n",
      "   [131. 130. 128.]]\n",
      "\n",
      "  [[101. 101. 103.]\n",
      "   [101. 101. 103.]\n",
      "   [101. 101. 103.]\n",
      "   ...\n",
      "   [136. 135. 133.]\n",
      "   [132. 131. 129.]\n",
      "   [128. 127. 125.]]]]\n"
     ]
    }
   ],
   "source": [
    "X_train = a[train_indices]\n",
    "print(len(X_train))\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = a[valid_indices]\n",
    "len(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (1318, 224, 224, 3)\n",
      "X_valid shape:  (328, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"X_valid shape: \",X_valid.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_labels = r'C:\\Users\\Aishwarya\\Documents\\GitHub\\Emergency-Vehicle-Recognition\\Python Notebook\\Data\\train\\train_names_labels.csv'\n",
    "\n",
    "df_train = pd.read_csv(path_to_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_names</th>\n",
       "      <th>emergency_or_not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_names  emergency_or_not\n",
       "0            0                 1\n",
       "1            1                 1\n",
       "2            2                 1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = np.array(df_train['emergency_or_not'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1646"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape:  (1318,)\n",
      "y_valid shape:  (328,)\n"
     ]
    }
   ],
   "source": [
    "y_train = all_labels[train_indices]\n",
    "y_valid = all_labels[valid_indices]\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"y_valid shape: \",y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1646, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Second component of main path \n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path \n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Adding shortcut value to main path, and passing it through a RELU activation \n",
    "    X = Add()([X,X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    # MAIN PATH\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding=\"valid\", kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Second component of main path \n",
    "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding=\"same\", kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path \n",
    "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding=\"valid\", kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    #SHORTCUT PATH \n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding=\"valid\", kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Adding shortcut value to main path, and passing it through a RELU activation \n",
    "    X = Add()([X_shortcut,X])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    \n",
    "\n",
    "    # Stage 3 (≈4 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [128,128,512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = X = AveragePooling2D(pool_size=(2, 2),name=\"avg_pool\")(X)\n",
    "    \n",
    "   \n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aishwarya\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Aishwarya\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(input_shape = (224, 224, 3), classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 1646\n",
      "X_train shape: (1318, 224, 224, 3)\n",
      "X_valid shape: (328, 224, 224, 3)\n",
      "y_train shape: (1318, 2)\n",
      "y_valid shape: (328, 2)\n"
     ]
    }
   ],
   "source": [
    "# Normalize image vectors\n",
    "X_train = X_train/255.\n",
    "X_valid = X_valid/255.\n",
    "# Convert training and test labels to one hot matrices\n",
    "y_train = convert_to_one_hot(y_train, 2).T\n",
    "y_valid = convert_to_one_hot(y_valid, 2).T\n",
    "print (\"Number of training examples = \" + str(a.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"X_valid shape: \" + str(X_valid.shape))\n",
    "print (\"y_train shape: \" + str(y_train.shape))\n",
    "print (\"y_valid shape: \" + str(y_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aishwarya\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/12\n",
      "1318/1318 [==============================] - 1716s 1s/step - loss: 3.2580 - accuracy: 0.5827\n",
      "Epoch 2/12\n",
      "1318/1318 [==============================] - 1790s 1s/step - loss: 1.2677 - accuracy: 0.6100\n",
      "Epoch 3/12\n",
      "1318/1318 [==============================] - 1982s 2s/step - loss: 0.9658 - accuracy: 0.5857\n",
      "Epoch 4/12\n",
      "1318/1318 [==============================] - 1968s 1s/step - loss: 0.6510 - accuracy: 0.6677\n",
      "Epoch 5/12\n",
      "1318/1318 [==============================] - 1902s 1s/step - loss: 0.5905 - accuracy: 0.7109\n",
      "Epoch 6/12\n",
      "1318/1318 [==============================] - 1969s 1s/step - loss: 0.5361 - accuracy: 0.7405\n",
      "Epoch 7/12\n",
      "1318/1318 [==============================] - 1663s 1s/step - loss: 0.5144 - accuracy: 0.7557\n",
      "Epoch 8/12\n",
      "1318/1318 [==============================] - 1451s 1s/step - loss: 0.4667 - accuracy: 0.7800\n",
      "Epoch 9/12\n",
      "1318/1318 [==============================] - 1406s 1s/step - loss: 0.4581 - accuracy: 0.8005\n",
      "Epoch 10/12\n",
      "1318/1318 [==============================] - 1379s 1s/step - loss: 0.4209 - accuracy: 0.8027\n",
      "Epoch 11/12\n",
      "1318/1318 [==============================] - 1453s 1s/step - loss: 0.3840 - accuracy: 0.8354\n",
      "Epoch 12/12\n",
      "1318/1318 [==============================] - 1705s 1s/step - loss: 0.3951 - accuracy: 0.8293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x192b5af26c8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 12, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the following few lines of code, we will try to evaluate our trained model on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 [==============================] - 133s 404ms/step\n",
      " Validation Set Loss = 0.5173940934785982\n",
      "Validation Set Accuracy = 0.75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preds = model.evaluate(X_valid, y_valid)\n",
    "print (\" Validation Set Loss = \" + str(preds[0]))\n",
    "print (\"Validation Set Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
